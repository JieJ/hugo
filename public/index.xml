<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My New Hugo Site</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on My New Hugo Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ch-en</language>
    <lastBuildDate>Tue, 08 Sep 2015 14:23:15 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>script</title>
      <link>http://localhost:1313/post/script/</link>
      <pubDate>Tue, 08 Sep 2015 14:23:15 +0800</pubDate>
      
      <guid>http://localhost:1313/post/script/</guid>
      <description></description>
    </item>
    
    <item>
      <title>blog</title>
      <link>http://localhost:1313/post/blog/</link>
      <pubDate>Tue, 08 Sep 2015 14:23:15 +0800</pubDate>
      
      <guid>http://localhost:1313/post/blog/</guid>
      <description>

&lt;h4 id=&#34;我不能忍:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;我不能忍！！！&lt;/h4&gt;

&lt;h4 id=&#34;一-coae2015-基于svm的中文微博观点倾向性识别:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;一、COAE2015：基于SVM的中文微博观点倾向性识别&lt;/h4&gt;

&lt;h5 id=&#34;用于主客观分类:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;用于主客观分类&lt;/h5&gt;

&lt;h6 id=&#34;句式特征:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;句式特征&lt;/h6&gt;

&lt;p&gt;否定词数量，语气词数量，问号数量，反问句式词数量， 感叹句数量，省略号数量&lt;/p&gt;

&lt;h6 id=&#34;句内特征:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;句内特征&lt;/h6&gt;

&lt;p&gt;动词数量，形容词数量，副词数量，情感词数量，评价词数量主观指示词数量
程度副词数量，人称代词数量， 数词数量，方位词谁昂，量词数量&lt;/p&gt;

&lt;h6 id=&#34;隐性特征-2-pos:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;隐性特征：2-POS&lt;/h6&gt;

&lt;p&gt;计算2-POS模型的卡方值（CHI），进行降序排列，取前5个2-POS项
第18个特征记为：&lt;/p&gt;

&lt;p&gt;$$ F18 = \sum_{i=1}^{5}x_i$$
其中i=1,2,3,4,5 $x_i$ 为CHI排名为i的2-POS模式的值
卡方值计算方式如下：
$$ \chi^2(pattern_i,O) = \frac{N \times (A \times D-C \times B)^2}{(A+C)(B+D)(A+B)(C+D)} $$&lt;/p&gt;

&lt;h5 id=&#34;2-用于情感值分类的特征:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;2. 用于情感值分类的特征&lt;/h5&gt;

&lt;h6 id=&#34;情感特征:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;情感特征&lt;/h6&gt;

&lt;p&gt;正面情感词数量，负面情感词数量，正面评价词数量，负面评价词数量&lt;/p&gt;

&lt;h6 id=&#34;句式特征-1:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;句式特征&lt;/h6&gt;

&lt;p&gt;程度副词数量，否定词数量，反问句式词数量，语气词数量，感叹号数量，问号数量，省略号数量&lt;/p&gt;

&lt;h6 id=&#34;词性特征:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;词性特征&lt;/h6&gt;

&lt;p&gt;动词数量，形容词数量，副词数量&lt;/p&gt;

&lt;h6 id=&#34;句间特征:e95c7dc8eefee7d0e25121cd7f0007ae&#34;&gt;句间特征&lt;/h6&gt;

&lt;p&gt;转折连词数量&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>neural network--backpropagation</title>
      <link>http://localhost:1313/post/neural%20network-3/</link>
      <pubDate>Tue, 08 Sep 2015 14:23:15 +0800</pubDate>
      
      <guid>http://localhost:1313/post/neural%20network-3/</guid>
      <description>

&lt;h4 id=&#34;how-the-backpropagation-algorithm-works:dc0e0e4f946020fd37f983facbed50cf&#34;&gt;How the backpropagation algorithm works&lt;/h4&gt;

&lt;h6 id=&#34;1-warm-up-a-fast-matrix-based-approach-to-computing-the-output-from-a-neural-network:dc0e0e4f946020fd37f983facbed50cf&#34;&gt;1. Warm up: a fast matrix-based approach to computing the output from a neural network&lt;/h6&gt;

&lt;p&gt;基于矩阵前向计算神经网络输出。&lt;/p&gt;

&lt;h6 id=&#34;2-the-two-assumptions-we-need-about-the-cost-function:dc0e0e4f946020fd37f983facbed50cf&#34;&gt;2. The two assumptions we need about the cost function&lt;/h6&gt;

&lt;ul&gt;
&lt;li&gt;cost function can be written as an average
$$ C = \frac {1}{n} \sum_xC_x $$&lt;/li&gt;
&lt;li&gt;cost function can be written as a function of the outputs from the neural network
$\begin{eqnarray} C = \frac{1}{2} |y-a^L|^2 = \frac{1}{2} \sum_j (y_j-a^L_j)^2,\tag{27}\end{eqnarray}$
对于输出层来说，我们就是这么做的。
但是对于隐藏层，如何将损失函数写成是关于这一层输出的函数呢？&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;3-the-hadamard-product-s-t:dc0e0e4f946020fd37f983facbed50cf&#34;&gt;3. The Hadamard product, s⊙t&lt;/h5&gt;

&lt;p&gt;elementwise multiplication
$\begin{eqnarray}
\left[\begin{array}{c} 1 \ 2 \end{array}\right]
  \odot \left[\begin{array}{c} 3 \ 4\end{array} \right]
= \left[ \begin{array}{c} 1 * 3 \ 2 * 4 \end{array} \right]
= \left[ \begin{array}{c} 3 \ 8 \end{array} \right].
\tag{28}\end{eqnarray}$&lt;/p&gt;

&lt;h5 id=&#34;4-the-four-fundamental-equations-behind-backpropagation:dc0e0e4f946020fd37f983facbed50cf&#34;&gt;4. The four fundamental equations behind backpropagation&lt;/h5&gt;

&lt;p&gt;首先计算神经元残差 $\delta^l&lt;em&gt;j$
再将残差与梯度 $\partial C/ \partial w^l&lt;/em&gt;{jk}$ 与 $\partial C/ \partial b^l&lt;em&gt;j$ 联系起来。
$\partial C/ \partial w^l&lt;/em&gt;{jk}$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>about</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Tue, 08 Sep 2015 14:22:47 +0800</pubDate>
      
      <guid>http://localhost:1313/about/</guid>
      <description>

&lt;h4 id=&#34;dddd:6083a88ee3411b0d17ce02d738f69d47&#34;&gt;dddd&lt;/h4&gt;
</description>
    </item>
    
  </channel>
</rss>